{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo #0, data preprocessing\n",
    "\n",
    "For this demonstration, we will be working with a few small bits of text, specifically, Shakespeare's sonnets. This dataset is very small, likely too small to train a usable language model.  However, this dataset presents a few interesting challenges, and will give us an opportunity to do some preprocessing and learning how to use many NLP Tools.\n",
    "\n",
    "The first step is to create a folder, then download the sonnets.  In this example, we will download them all as one big text document, then split them into the individual sonnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shakespeares-sonnets_TXT_FolgerShakespeare.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.makedirs('Sonnets')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.chdir('Sonnets')\n",
    "except:\n",
    "    pass\n",
    "wget.download('https://shakespeare.folger.edu/downloads/txt/shakespeares-sonnets_TXT_FolgerShakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to break this file down into the sonnets, here is one way.  This step is not necessarily the most important, as long as all of the data has been preserved. We don't want to do too much processing right now, because we want the \"ground truth observations\" to be preserved in case the model needs to be retrained.\n",
    "\n",
    "Generally, it's more understandable if all of the processing happens at once, just before the data is used to train a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Processing: Sonnet_001.txt\n",
      "Now Processing: Sonnet_002.txt\n",
      "Now Processing: Sonnet_003.txt\n",
      "Now Processing: Sonnet_004.txt\n",
      "Now Processing: Sonnet_005.txt\n",
      "Now Processing: Sonnet_006.txt\n",
      "Now Processing: Sonnet_007.txt\n",
      "Now Processing: Sonnet_008.txt\n",
      "Now Processing: Sonnet_009.txt\n",
      "Now Processing: Sonnet_010.txt\n",
      "Now Processing: Sonnet_011.txt\n",
      "Now Processing: Sonnet_012.txt\n",
      "Now Processing: Sonnet_013.txt\n",
      "Now Processing: Sonnet_014.txt\n",
      "Now Processing: Sonnet_015.txt\n",
      "Now Processing: Sonnet_016.txt\n",
      "Now Processing: Sonnet_017.txt\n",
      "Now Processing: Sonnet_018.txt\n",
      "Now Processing: Sonnet_019.txt\n",
      "Now Processing: Sonnet_020.txt\n",
      "Now Processing: Sonnet_021.txt\n",
      "Now Processing: Sonnet_022.txt\n",
      "Now Processing: Sonnet_023.txt\n",
      "Now Processing: Sonnet_024.txt\n",
      "Now Processing: Sonnet_025.txt\n",
      "Now Processing: Sonnet_026.txt\n",
      "Now Processing: Sonnet_027.txt\n",
      "Now Processing: Sonnet_028.txt\n",
      "Now Processing: Sonnet_029.txt\n",
      "Now Processing: Sonnet_030.txt\n",
      "Now Processing: Sonnet_031.txt\n",
      "Now Processing: Sonnet_032.txt\n",
      "Now Processing: Sonnet_033.txt\n",
      "Now Processing: Sonnet_034.txt\n",
      "Now Processing: Sonnet_035.txt\n",
      "Now Processing: Sonnet_036.txt\n",
      "Now Processing: Sonnet_037.txt\n",
      "Now Processing: Sonnet_038.txt\n",
      "Now Processing: Sonnet_039.txt\n",
      "Now Processing: Sonnet_040.txt\n",
      "Now Processing: Sonnet_041.txt\n",
      "Now Processing: Sonnet_042.txt\n",
      "Now Processing: Sonnet_043.txt\n",
      "Now Processing: Sonnet_044.txt\n",
      "Now Processing: Sonnet_045.txt\n",
      "Now Processing: Sonnet_046.txt\n",
      "Now Processing: Sonnet_047.txt\n",
      "Now Processing: Sonnet_048.txt\n",
      "Now Processing: Sonnet_049.txt\n",
      "Now Processing: Sonnet_050.txt\n",
      "Now Processing: Sonnet_051.txt\n",
      "Now Processing: Sonnet_052.txt\n",
      "Now Processing: Sonnet_053.txt\n",
      "Now Processing: Sonnet_054.txt\n",
      "Now Processing: Sonnet_055.txt\n",
      "Now Processing: Sonnet_056.txt\n",
      "Now Processing: Sonnet_057.txt\n",
      "Now Processing: Sonnet_058.txt\n",
      "Now Processing: Sonnet_059.txt\n",
      "Now Processing: Sonnet_060.txt\n",
      "Now Processing: Sonnet_061.txt\n",
      "Now Processing: Sonnet_062.txt\n",
      "Now Processing: Sonnet_063.txt\n",
      "Now Processing: Sonnet_064.txt\n",
      "Now Processing: Sonnet_065.txt\n",
      "Now Processing: Sonnet_066.txt\n",
      "Now Processing: Sonnet_067.txt\n",
      "Now Processing: Sonnet_068.txt\n",
      "Now Processing: Sonnet_069.txt\n",
      "Now Processing: Sonnet_070.txt\n",
      "Now Processing: Sonnet_071.txt\n",
      "Now Processing: Sonnet_072.txt\n",
      "Now Processing: Sonnet_073.txt\n",
      "Now Processing: Sonnet_074.txt\n",
      "Now Processing: Sonnet_075.txt\n",
      "Now Processing: Sonnet_076.txt\n",
      "Now Processing: Sonnet_077.txt\n",
      "Now Processing: Sonnet_078.txt\n",
      "Now Processing: Sonnet_079.txt\n",
      "Now Processing: Sonnet_080.txt\n",
      "Now Processing: Sonnet_081.txt\n",
      "Now Processing: Sonnet_082.txt\n",
      "Now Processing: Sonnet_083.txt\n",
      "Now Processing: Sonnet_084.txt\n",
      "Now Processing: Sonnet_085.txt\n",
      "Now Processing: Sonnet_086.txt\n",
      "Now Processing: Sonnet_087.txt\n",
      "Now Processing: Sonnet_088.txt\n",
      "Now Processing: Sonnet_089.txt\n",
      "Now Processing: Sonnet_090.txt\n",
      "Now Processing: Sonnet_091.txt\n",
      "Now Processing: Sonnet_092.txt\n",
      "Now Processing: Sonnet_093.txt\n",
      "Now Processing: Sonnet_094.txt\n",
      "Now Processing: Sonnet_095.txt\n",
      "Now Processing: Sonnet_096.txt\n",
      "Now Processing: Sonnet_097.txt\n",
      "Now Processing: Sonnet_098.txt\n",
      "Now Processing: Sonnet_099.txt\n",
      "Now Processing: Sonnet_100.txt\n",
      "Now Processing: Sonnet_101.txt\n",
      "Now Processing: Sonnet_102.txt\n",
      "Now Processing: Sonnet_103.txt\n",
      "Now Processing: Sonnet_104.txt\n",
      "Now Processing: Sonnet_105.txt\n",
      "Now Processing: Sonnet_106.txt\n",
      "Now Processing: Sonnet_107.txt\n",
      "Now Processing: Sonnet_108.txt\n",
      "Now Processing: Sonnet_109.txt\n",
      "Now Processing: Sonnet_110.txt\n",
      "Now Processing: Sonnet_111.txt\n",
      "Now Processing: Sonnet_112.txt\n",
      "Now Processing: Sonnet_113.txt\n",
      "Now Processing: Sonnet_114.txt\n",
      "Now Processing: Sonnet_115.txt\n",
      "Now Processing: Sonnet_116.txt\n",
      "Now Processing: Sonnet_117.txt\n",
      "Now Processing: Sonnet_118.txt\n",
      "Now Processing: Sonnet_119.txt\n",
      "Now Processing: Sonnet_120.txt\n",
      "Now Processing: Sonnet_121.txt\n",
      "Now Processing: Sonnet_122.txt\n",
      "Now Processing: Sonnet_123.txt\n",
      "Now Processing: Sonnet_124.txt\n",
      "Now Processing: Sonnet_125.txt\n",
      "Now Processing: Sonnet_126.txt\n",
      "Now Processing: Sonnet_127.txt\n",
      "Now Processing: Sonnet_128.txt\n",
      "Now Processing: Sonnet_129.txt\n",
      "Now Processing: Sonnet_130.txt\n",
      "Now Processing: Sonnet_131.txt\n",
      "Now Processing: Sonnet_132.txt\n",
      "Now Processing: Sonnet_133.txt\n",
      "Now Processing: Sonnet_134.txt\n",
      "Now Processing: Sonnet_135.txt\n",
      "Now Processing: Sonnet_136.txt\n",
      "Now Processing: Sonnet_137.txt\n",
      "Now Processing: Sonnet_138.txt\n",
      "Now Processing: Sonnet_139.txt\n",
      "Now Processing: Sonnet_140.txt\n",
      "Now Processing: Sonnet_141.txt\n",
      "Now Processing: Sonnet_142.txt\n",
      "Now Processing: Sonnet_143.txt\n",
      "Now Processing: Sonnet_144.txt\n",
      "Now Processing: Sonnet_145.txt\n",
      "Now Processing: Sonnet_146.txt\n",
      "Now Processing: Sonnet_147.txt\n",
      "Now Processing: Sonnet_148.txt\n",
      "Now Processing: Sonnet_149.txt\n",
      "Now Processing: Sonnet_150.txt\n",
      "Now Processing: Sonnet_151.txt\n",
      "Now Processing: Sonnet_152.txt\n",
      "Now Processing: Sonnet_153.txt\n",
      "Now Processing: Sonnet_154.txt\n"
     ]
    }
   ],
   "source": [
    "with open('shakespeares-sonnets_TXT_FolgerShakespeare.txt', 'r') as raw_text:\n",
    "    for line_number, line in enumerate(raw_text):\n",
    "        try:\n",
    "            int(line)\n",
    "            line_number = line.strip()\n",
    "            sonnet_name = \"Sonnet_\" + line_number.zfill(3) + '.txt'\n",
    "            print(\"Now Processing: \"+ sonnet_name)\n",
    "            active_sonnet = open(sonnet_name, 'w')\n",
    "        except:\n",
    "            if line == '\\n':\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    active_sonnet.write(line)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "\n",
    "Predefined stop words we can use in gensim are sourced from https://gist.github.com/sebleier/554280\n",
    "We cannot use a stop-word list that includes gendered pronouns because much of shakespeare's work involved\n",
    "talking about his two lovers, the golden boy and the dark lady, so gender is very important to our corpus\n",
    "of text. We cannot use the default stop words, because it is inappropriate for the data we are looking at.\n",
    "\n",
    "We must therefore define our own list of stop words.  I'm going to demonstrate how to create and edit a config\n",
    "file using python, but you can do this just as easily using a plaintext editor like sublime or notepad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'about', 'actually', 'almost', 'also', 'although', \n",
    "              'always', 'am', 'an', 'and', 'any', 'are', 'as', 'at', \n",
    "              'be', 'became', 'become', 'but', 'by', 'can', 'could', \n",
    "              'did', 'do', 'does', 'each', 'either', 'else', 'for', \n",
    "              'from', 'had', 'has', 'have', 'hence', 'how', 'i', 'if', \n",
    "              'in', 'is', 'it', 'its', 'just', 'may', 'maybe', 'me', \n",
    "              'might', 'mine', 'must', 'my', 'mine', 'must', 'my', \n",
    "              'neither', 'nor', 'not', 'of', 'oh', 'ok', 'when', 'where', \n",
    "              'whereas', 'wherever', 'whenever', 'whether', 'which', 'while', \n",
    "              'who', 'whom', 'whoever', 'whose', 'why', 'will', 'with', \n",
    "              'within', 'without', 'would', 'yes', 'yet', 'you', 'your']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'w') as stop_word_file:\n",
    "    #stop_word_file.write('[')\n",
    "    for word in stop_words:\n",
    "            stop_word_file.write(word + '\\n')\n",
    "    #stop_word_file.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
